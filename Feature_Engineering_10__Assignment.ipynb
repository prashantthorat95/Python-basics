{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MACHINE LEARNING ASSIGNMENT"
      ],
      "metadata": {
        "id": "QslhgstsKWQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 1: What is a parameter?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In statistics and machine learning, a **parameter** is a **fixed, numerical value that describes a property of a population or a model**.\n",
        "\n",
        "- In **statistics**:  \n",
        "  - Population mean (Œº), population variance (œÉ¬≤) are parameters.\n",
        "- In **machine learning models**:  \n",
        "  - The **weights and biases** of a model are parameters (for example, slope and intercept in linear regression).\n",
        "\n",
        "Once a model is trained, its parameters represent the **learned knowledge** from the data.\n",
        "\n",
        "**Example (Linear Regression):**\n",
        "\n",
        "For a model:\n",
        "\n",
        "\\[\n",
        "y = w x + b\n",
        "\\]\n",
        "\n",
        "- \\(w\\) = weight (parameter)  \n",
        "- \\(b\\) = bias (parameter)  \n",
        "\n",
        "These are learned during training.\n"
      ],
      "metadata": {
        "id": "oVVVl4GjKV2B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7CXBUdqLWQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 2: What is correlation?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Correlation** is a statistical measure that tells us **how strongly two variables are related to each other** and **in which direction**.\n",
        "\n",
        "- If one variable increases and the other also tends to increase ‚Üí **positive correlation**\n",
        "- If one variable increases and the other tends to decrease ‚Üí **negative correlation**\n",
        "- If there is no pattern between them ‚Üí **no correlation**\n",
        "\n",
        "The most common measure is the **Pearson correlation coefficient (r)**, which ranges from **‚àí1 to +1**:\n",
        "\n",
        "- **+1** ‚Üí perfect positive correlation  \n",
        "- **0** ‚Üí no linear correlation  \n",
        "- **‚àí1** ‚Üí perfect negative correlation  \n",
        "\n",
        "In machine learning, we use correlation to **understand relationships between features and target**, and reduce redundant features.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eXC_pUfALXDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  What does negative correlation mean?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "A **negative correlation** means that:\n",
        "\n",
        "> As one variable **increases**, the other variable **tends to decrease**, and vice versa.\n",
        "\n",
        "So they move in **opposite directions**.\n",
        "\n",
        "- Example:  \n",
        "  - Number of hours spent **watching TV** and **exam scores**  \n",
        "    - More TV ‚Üí lower scores (usually) ‚Üí **negative correlation**\n",
        "\n",
        "In terms of correlation coefficient:\n",
        "\n",
        "- **Negative correlation** ‚Üí correlation value **less than 0** (e.g., ‚àí0.3, ‚àí0.8).\n",
        "\n",
        "In machine learning, negative correlation helps us understand that one feature **reduces** as another **increases**.\n"
      ],
      "metadata": {
        "id": "CH44vLxplQou"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4ZLG9fVLaP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yjk9DFn0L1NU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0xLlZDyL2dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 3: Define Machine Learning. What are the main components in Machine Learning?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Machine Learning (ML)** is a field of computer science where **algorithms learn patterns from data** to make predictions or decisions **without being explicitly programmed for each task**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Main Components in Machine Learning**\n",
        "\n",
        "1. **Data**\n",
        "   - Input to the model\n",
        "   - Features (X) and sometimes labels/target (y)\n",
        "\n",
        "2. **Features (Input Variables)**\n",
        "   - Individual measurable properties (e.g., age, salary, temperature).\n",
        "\n",
        "3. **Model**\n",
        "   - The mathematical function that maps inputs to outputs  \n",
        "   - Examples: Linear Regression, Decision Tree, Neural Network\n",
        "\n",
        "4. **Loss/Cost Function**\n",
        "   - Measures the **error** between predicted and actual values  \n",
        "   - Example: Mean Squared Error for regression\n",
        "\n",
        "5. **Training Algorithm / Optimizer**\n",
        "   - Adjusts model parameters to **minimize loss**  \n",
        "   - Example: Gradient Descent, Adam\n",
        "\n",
        "6. **Evaluation**\n",
        "   - Metrics to check performance  \n",
        "   - Example: Accuracy, RMSE, Precision, Recall\n",
        "\n",
        "7. **Prediction / Inference**\n",
        "   - Using the trained model on **new, unseen data**.\n",
        "\n",
        "These components work together to build, train, and evaluate ML systems.\n"
      ],
      "metadata": {
        "id": "rVLsiaNBL2uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWZH08cwMfa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4: How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The **loss value** (or cost) measures **how wrong the model‚Äôs predictions are** compared to the actual values.\n",
        "\n",
        "- **Low loss** ‚Üí model is making predictions close to true values ‚Üí **better model**\n",
        "- **High loss** ‚Üí large errors ‚Üí **poor model**\n",
        "\n",
        "During training:\n",
        "\n",
        "- The goal of the optimizer is to **minimize the loss function**.\n",
        "- As training progresses:\n",
        "  - If loss **decreases**, the model is **learning**.\n",
        "  - If loss is **not decreasing** or **increasing**, the model may be:\n",
        "    - Underfitting\n",
        "    - Overfitting\n",
        "    - Using wrong learning rate / architecture\n",
        "\n",
        "So, loss is a **numerical indicator** that helps us decide:\n",
        "\n",
        "- Is the model improving?  \n",
        "- Is this model configuration good or bad?  \n",
        "- Should we stop training or change hyperparameters?\n"
      ],
      "metadata": {
        "id": "ADJ9N50VMfxt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMU1zMY-Qym6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 5: What are continuous and categorical variables?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "#### **Continuous Variables**\n",
        "- Variables that can take **any numerical value** within a range, including decimals.\n",
        "- Examples:\n",
        "  - Height (172.5 cm)\n",
        "  - Temperature (36.8¬∞C)\n",
        "  - Salary (‚Çπ52,500.75)\n",
        "\n",
        "These are usually **measured**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Categorical Variables**\n",
        "- Variables that represent **categories or groups**, not numbers with mathematical meaning.\n",
        "- Examples:\n",
        "  - Gender: Male, Female, Other\n",
        "  - City: Mumbai, Pune, Delhi\n",
        "  - Color: Red, Blue, Green\n",
        "\n",
        "They can be:\n",
        "- **Nominal** (no order) ‚Üí colors, city names  \n",
        "- **Ordinal** (with order) ‚Üí ratings: low, medium, high\n",
        "\n",
        "In ML, continuous variables are often used **directly**, while categorical variables usually need **encoding** into numbers.\n"
      ],
      "metadata": {
        "id": "i86MmpByQxgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9oFssoATREc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 6: How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What are categorical variables?**\n",
        "\n",
        "Categorical variables are features that contain **text or labels instead of numeric values**.  \n",
        "Examples:\n",
        "- Gender: Male, Female\n",
        "- City: Mumbai, Delhi, Pune\n",
        "- Color: Red, Blue, Green\n",
        "\n",
        "Most machine learning algorithms **cannot process text labels directly**, so we must **convert categorical variables into numeric form**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why do we need to encode categorical variables?**\n",
        "\n",
        "Machine learning models work on **numbers**, not **words**.  \n",
        "Therefore, categorical data must be **encoded into numerical format** so the model can learn patterns from it.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Common Techniques to Handle Categorical Variables**\n",
        "\n",
        "#### **A. Label Encoding**\n",
        "- Assigns **integer numbers** to each category.\n",
        "- Example:  \n",
        "  Colors ‚Üí Red = 0, Blue = 1, Green = 2\n",
        "- Useful for **ordinal (ordered)** categories like: Low < Medium < High\n",
        "- Not recommended for **non-ordered (nominal)** categories because numbers may imply false ranking.\n",
        "\n",
        "#### **B. One-Hot Encoding**\n",
        "- Creates **new binary columns** (0 or 1) for each category.\n",
        "- Example (City):\n",
        "  | City_Mumbai | City_Delhi | City_Pune |\n",
        "  |-------------|------------|-----------|\n",
        "  | 1           | 0          | 0         |\n",
        "  | 0           | 1          | 0         |\n",
        "- No ranking issue ‚Üí best for **nominal** categories.\n",
        "- Can increase dataset size if categories are many.\n",
        "\n",
        "#### **C. Ordinal Encoding**\n",
        "- Converts categories to numbers **based on order**.\n",
        "- Example:\n",
        "  Education level:\n",
        "  - High School ‚Üí 1\n",
        "  - Graduate ‚Üí 2\n",
        "  - Postgraduate ‚Üí 3\n",
        "- Only valid when order of categories **matters**.\n",
        "\n",
        "#### **D. Target Encoding**\n",
        "- Replace each category with the **mean of the target variable** within that category.\n",
        "- Example (binary classification):  \n",
        "  If ‚ÄúMale‚Äù has default rate 0.10 and ‚ÄúFemale‚Äù has 0.06 ‚Üí replace them with 0.10 and 0.06.\n",
        "- Useful for **high-cardinality features** (many unique categories).\n",
        "- Risk of **overfitting** if not regularized properly.\n",
        "\n",
        "#### **E. Frequency / Count Encoding**\n",
        "- Replaces each category with **how often it appears in the dataset**.\n",
        "- Example:  \n",
        "  - Delhi (120 times) ‚Üí 120  \n",
        "  - Mumbai (200 times) ‚Üí 200\n",
        "- Keeps dataset compact and avoids dimensionality explosion.\n",
        "\n",
        "#### **F. Binary Encoding**\n",
        "- First converts categories to numbers and then to **binary format**.\n",
        "- Good for **very high unique categories** (e.g., thousands of cities).\n",
        "- Balanced trade-off between One-Hot and Label Encoding.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Choosing the Right Technique**\n",
        "\n",
        "| Data Type (Category)        | Best Encoding Method                       |\n",
        "|-----------------------------|-------------------------------------------|\n",
        "| Ordinal (ordered)           | Ordinal / Label Encoding                  |\n",
        "| Nominal (no order)          | One-Hot Encoding, Binary Encoding         |\n",
        "| High cardinality (many categories) | Target Encoding / Frequency Encoding |\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Summary**\n",
        "\n",
        "Handling categorical variables is a crucial step in Machine Learning because models require numeric input.  \n",
        "The **most common encoding techniques** are:\n",
        "- Label Encoding\n",
        "- One-Hot Encoding\n",
        "- Ordinal Encoding\n",
        "- Target Encoding\n",
        "- Frequency Encoding\n",
        "- Binary Encoding\n",
        "\n",
        "Correct encoding improves **model learning, performance, and accuracy**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1fcWqxkqRE5T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvuGOsDmRHB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 7: What do you mean by training and testing a dataset?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In machine learning, we usually **split data into two (or three) parts**:\n",
        "\n",
        "1. **Training Set**\n",
        "   - Used to **train the model**.\n",
        "   - Model learns patterns and adjusts its parameters.\n",
        "\n",
        "2. **Test Set**\n",
        "   - Used to **evaluate the performance** of the trained model on **unseen data**.\n",
        "   - Helps us understand how well the model generalizes.\n",
        "\n",
        "Sometimes we also use:\n",
        "\n",
        "3. **Validation Set**\n",
        "   - Used to tune hyperparameters and select the best model.\n",
        "\n",
        "**Why split?**\n",
        "\n",
        "- If we train and test on the **same data**, we may get an **unrealistic high accuracy** (overfitting).\n",
        "- Testing on new data gives a more **honest estimate** of model performance.\n"
      ],
      "metadata": {
        "id": "XEA5i7oyRHXG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDOrZUOSRHrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 8: What is `sklearn.preprocessing`?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Simple Definition**\n",
        "\n",
        "`sklearn.preprocessing` is a **module in Scikit-Learn (sklearn)** that contains tools for **preprocessing and transforming data before training a machine learning model**.\n",
        "\n",
        "Preprocessing means converting raw data into a **clean and suitable format** so that a ML model can understand and learn from it properly.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why is preprocessing needed?**\n",
        "\n",
        "Real-world data often contains:\n",
        "- Categorical values\n",
        "- Different scales (e.g., age 25 vs. salary 60,000)\n",
        "- Missing values\n",
        "- Noise or outliers\n",
        "\n",
        "Machine Learning algorithms work better when:\n",
        "- Data is **normalized or standardized**\n",
        "- Categorical values are **encoded**\n",
        "- Numerical values are **scaled**\n",
        "\n",
        "Therefore, preprocessing improves:\n",
        "- Model performance\n",
        "- Accuracy\n",
        "- Speed of training\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What can `sklearn.preprocessing` do? (Main Functions)**\n",
        "\n",
        "| Task | Method / Class | Purpose |\n",
        "|------|----------------|---------|\n",
        "| Scaling / Normalizing | `StandardScaler`, `MinMaxScaler`, `Normalizer` | Makes numerical values comparable |\n",
        "| Encoding categorical data | `OneHotEncoder`, `LabelEncoder`, `OrdinalEncoder` | Converts categories to numbers |\n",
        "| Binarization | `Binarizer` | Converts values to 0 or 1 based on threshold |\n",
        "| Polynomial features | `PolynomialFeatures` | Adds new polynomial features to data |\n",
        "| Missing value handling | (via `Imputer` in sklearn.impute module) | Fills missing values (not part of preprocessing module now) |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Common Examples**\n",
        "\n",
        "#### **A. Standard Scaling**\n",
        "Helps when features have very different scales.\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "I12Qhur_RIE7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSNopyXURIrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 9: What is a Test Set?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Simple Definition**\n",
        "\n",
        "A **test set** is a portion of the dataset that is **kept separate from training data** and is used **to evaluate the performance of a machine learning model after training**.\n",
        "\n",
        "The model **never sees** the test set during training.  \n",
        "It is used only to check how well the model performs on **new and unseen data**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why do we need a Test Set?**\n",
        "\n",
        "If we evaluate the model on the **same data used for training**, the model may:\n",
        "- Memorize the training data\n",
        "- Show high accuracy on training data\n",
        "- But perform poorly on new data  \n",
        "  ‚Üí This problem is called **overfitting**\n",
        "\n",
        "A test set helps determine whether the model can **generalize** to real-world data.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What the Test Set Measures**\n",
        "\n",
        "The test set is used to calculate:\n",
        "- Accuracy\n",
        "- Error rate\n",
        "- Precision & Recall (for classification)\n",
        "- RMSE / MAE (for regression)\n",
        "- F1-score, R¬≤, etc.\n",
        "\n",
        "A good model performs **well on both**:\n",
        "- Training set\n",
        "- Test set\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Typical Dataset Split**\n",
        "\n",
        "| Dataset Type | Purpose | Used When |\n",
        "|-------------|---------|-----------|\n",
        "| **Training Set** | To train the model | During training |\n",
        "| **Test Set** | To evaluate the model | After training |\n",
        "\n",
        "Common split ratios:\n",
        "- 80% training ‚Äî 20% testing\n",
        "- 70% training ‚Äî 30% testing\n",
        "- 75% training ‚Äî 25% testing\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Real-Life Analogy**\n",
        "\n",
        "Learning for an exam:\n",
        "- **Practice questions (training set):** You study and practice to learn concepts.\n",
        "- **Final exam (test set):** A completely new exam that checks whether you truly understand the subject.\n",
        "\n",
        "You don‚Äôt see the final exam questions while preparing ‚Äî just like a model doesn‚Äôt see the test set during training.\n",
        "\n",
        "---\n",
        "\n",
        "### **In summary**\n",
        "\n",
        "A **test set** is a subset of data used **after training** to evaluate how well a machine learning model performs on **new, unseen data**.  \n",
        "It is essential for checking a model‚Äôs **accuracy, generalization ability, and real-world performance**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ebxwmvu2S7Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLF0izbTRJaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 10: How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "---\n",
        "\n",
        "To train and evaluate a machine learning model properly, the dataset must be **divided into two parts**:\n",
        "\n",
        "| Part | Purpose |\n",
        "|------|----------|\n",
        "| **Training Set** | Used to teach the model and adjust parameters |\n",
        "| **Testing Set** | Used to evaluate how well the trained model performs on new/unseen data |\n",
        "\n",
        "The most common way to split data in Python is using:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "cCNzeDGbRJor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4, 6, 1, 7, 9, 5],\n",
        "    \"Attendance\":    [60, 90, 75, 95, 70, 88, 55, 92, 98, 85],\n",
        "    \"Marks\":         [45, 88, 60, 92, 65, 80, 35, 89, 96, 78]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separating features (X) and target (y)\n",
        "X = df[[\"Hours_Studied\", \"Attendance\"]]\n",
        "y = df[\"Marks\"]\n",
        "\n",
        "# Splitting data for model fitting (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"üìå Original Dataset Shape:\", df.shape)\n",
        "print(\"üìå Training Set Shape:\", X_train.shape, \"|\", y_train.shape)\n",
        "print(\"üìå Testing Set Shape :\", X_test.shape,  \"|\", y_test.shape)\n",
        "\n",
        "print(\"\\nüîπ Training Data:\")\n",
        "print(pd.concat([X_train, y_train], axis=1))\n",
        "\n",
        "print(\"\\nüîπ Testing Data:\")\n",
        "print(pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2seZbG1QRJ9S",
        "outputId": "b95d5946-0961-4d00-b6aa-96668b98bc72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå Original Dataset Shape: (10, 3)\n",
            "üìå Training Set Shape: (8, 2) | (8,)\n",
            "üìå Testing Set Shape : (2, 2) | (2,)\n",
            "\n",
            "üîπ Training Data:\n",
            "   Hours_Studied  Attendance  Marks\n",
            "5              6          88     80\n",
            "0              2          60     45\n",
            "7              7          92     89\n",
            "2              3          75     60\n",
            "9              5          85     78\n",
            "4              4          70     65\n",
            "3              8          95     92\n",
            "6              1          55     35\n",
            "\n",
            "üîπ Testing Data:\n",
            "   Hours_Studied  Attendance  Marks\n",
            "8              9          98     96\n",
            "1              5          90     88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mdh7fB2HTv55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 11 : Why do we have to perform EDA before fitting a model to the data? (Simple words)**\n",
        "\n",
        "EDA (Exploratory Data Analysis) means **studying and understanding the data before building a model**.\n",
        "\n",
        "We perform EDA because:\n",
        "\n",
        "---\n",
        "\n",
        "### **Reasons (in simple words)**\n",
        "\n",
        "‚úî To **know what the data contains**  \n",
        "‚úî To **find mistakes** in the data (missing values, wrong values)  \n",
        "‚úî To **detect outliers** (very extreme values that can confuse the model)  \n",
        "‚úî To **understand relationships** between features and target  \n",
        "‚úî To **decide which features are important** and which are not  \n",
        "‚úî To **choose the right preprocessing techniques** (scaling, encoding, etc.)\n",
        "\n",
        "---\n",
        "\n",
        "### **What happens if we skip EDA?**\n",
        "If we fit a model without checking the data:\n",
        "- The model may learn **wrong patterns**\n",
        "- It may become **less accurate**\n",
        "- It may get **confused by noise or missing values**\n",
        "- Model performance becomes **poor in real-world use**\n",
        "\n",
        "---\n",
        "\n",
        "### **In simple short summary**\n",
        "> EDA helps us clean, understand, and prepare the data properly so the model can learn correctly and give high accuracy.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "b8du5fe6obKR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptAmewokoxfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 12: What is correlation?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Simple Definition**\n",
        "\n",
        "**Correlation** is a statistical measure that describes the **strength and direction of a relationship between two variables**.\n",
        "\n",
        "In simple words:\n",
        "> Correlation tells us whether changes in one variable are associated with changes in another variable.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Types of Correlation**\n",
        "\n",
        "| Type | Meaning | Example |\n",
        "|------|---------|---------|\n",
        "| **Positive correlation** | Both variables increase or decrease together | Hours studied ‚Üë ‚Üí Marks ‚Üë |\n",
        "| **Negative correlation** | One variable increases while the other decreases | Exercise ‚Üë ‚Üí Weight ‚Üì |\n",
        "| **Zero (no) correlation** | No relationship between the variables | Shoe size vs Marks |\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Correlation Coefficient (r)**\n",
        "\n",
        "The strength of correlation is expressed using the **correlation coefficient (r)**, which ranges from **-1 to +1**:\n",
        "\n",
        "| Value of r | Interpretation |\n",
        "|------------|----------------|\n",
        "| +1 | Perfect positive correlation |\n",
        "| 0.7 to 0.9 | Strong positive correlation |\n",
        "| 0.3 to 0.7 | Moderate positive correlation |\n",
        "| 0 to 0.3 | Weak/no correlation |\n",
        "| -0.3 to -0.7 | Moderate negative correlation |\n",
        "| -0.7 to -1 | Strong negative correlation |\n",
        "| -1 | Perfect negative correlation |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Visual Understanding**\n",
        "\n",
        "| Graph | Meaning |\n",
        "|-------|--------|\n",
        "| ‚Üó | Strong positive correlation |\n",
        "| ‚Üò | Strong negative correlation |\n",
        "| Scatter with no pattern | No correlation |\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Why is correlation important in Data Science / ML?**\n",
        "\n",
        "Correlation helps us:\n",
        "- Identify relationships between variables\n",
        "- Understand which features are useful for prediction\n",
        "- Detect multicollinearity (when features are strongly correlated with each other)\n",
        "\n",
        "Example:\n",
        "- If **height** and **weight** have high correlation, using **both** might not add much value to the model.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Example**\n",
        "\n",
        "If we calculate correlation between:\n",
        "| Hours studied | Marks |\n",
        "|---------------|-------|\n",
        "| 2 | 45 |\n",
        "| 5 | 88 |\n",
        "| 3 | 60 |\n",
        "| 8 | 92 |\n",
        "\n",
        "We would find a **strong positive correlation**:\n",
        "> As hours studied increase ‚Üí marks also increase.\n",
        "\n",
        "---\n",
        "\n",
        "### **In summary**\n",
        "\n",
        "- **Correlation** measures how strongly two variables are related.\n",
        "- It tells whether variables move **together**, **opposite**, or **not related**.\n",
        "- Value of **r ranges from ‚Äì1 to +1** and indicates the **strength and direction** of the relationship.\n",
        "- Correlation is essential in **data analysis and machine learning** for selecting useful features.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0gYV_8niTyTy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSgeJTtCTy1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 13: What does negative correlation mean?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Simple Definition**\n",
        "\n",
        "A **negative correlation** means that **when one variable increases, the other variable decreases**, and vice versa.\n",
        "\n",
        "In other words:\n",
        "> Two variables move in **opposite directions**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Correlation Coefficient Interpretation**\n",
        "\n",
        "Negative correlation values range from **0 to ‚Äì1**:\n",
        "\n",
        "| Correlation Value (r) | Meaning |\n",
        "|-----------------------|---------|\n",
        "| ‚Äì1 | Perfect negative correlation |\n",
        "| ‚Äì0.7 to ‚Äì1 | Strong negative correlation |\n",
        "| ‚Äì0.3 to ‚Äì0.7 | Moderate negative correlation |\n",
        "| 0 to ‚Äì0.3 | Weak negative correlation |\n",
        "\n",
        "A value of **‚Äì1** means variables are perfectly opposite.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Examples of Negative Correlation**\n",
        "\n",
        "| Variable A ‚Üë | Variable B ‚Üì |\n",
        "|--------------|--------------|\n",
        "| Exercise increases | Body weight decreases |\n",
        "| Speed of vehicle increases | Travel time decreases |\n",
        "| Price of product increases | Quantity purchased decreases |\n",
        "| Temperature decreases | Electricity bill increases (due to heater use) |\n",
        "\n",
        "In each case, the two variables move in **opposite directions**.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Visual Understanding**\n",
        "\n",
        "Negative correlation on a scatter plot looks like this:\n",
        "\n"
      ],
      "metadata": {
        "id": "OHHF7YnDTzf4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VZHgBdYfTD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 14: How can you find correlation between variables in Python?**\n",
        "\n",
        "---\n",
        "\n",
        "To measure how strongly variables are related, we calculate **correlation**.  \n",
        "Python provides simple and powerful tools to compute correlation using libraries like **Pandas**, **NumPy**, and **Seaborn** (for visualization).\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Finding Correlation Using Pandas**\n",
        "\n",
        "The most common method:\n",
        "\n",
        "```python\n",
        "df.corr()\n"
      ],
      "metadata": {
        "id": "zE_Z79fhfR6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4, 6, 1, 7, 9, 5],\n",
        "    \"Attendance\":    [60, 90, 75, 95, 70, 88, 55, 92, 98, 85],\n",
        "    \"Marks\":         [45, 88, 60, 92, 65, 80, 35, 89, 96, 78]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1Ô∏è‚É£ Correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "print(\"Correlation Matrix:\")\n",
        "print(corr_matrix)\n",
        "\n",
        "# 2Ô∏è‚É£ Visualizing correlation using heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "yuyx7ciYfdLF",
        "outputId": "d75cb23d-b6ea-49dc-9598-fcdf98b66a67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "               Hours_Studied  Attendance     Marks\n",
            "Hours_Studied       1.000000    0.943721  0.946119\n",
            "Attendance          0.943721    1.000000  0.987883\n",
            "Marks               0.946119    0.987883  1.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZZ11hEdflfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 15: What is causation? Explain the difference between correlation and causation with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What is Causation?**\n",
        "\n",
        "**Causation (Cause-and-Effect)** means that **a change in one variable directly produces a change in another variable**.\n",
        "\n",
        "In simple words:\n",
        "> Variable A **causes** variable B to change.\n",
        "\n",
        "Example:\n",
        "- More hours of study ‚Üí leads to **higher marks**\n",
        "- Good diet ‚Üí leads to **better health**\n",
        "\n",
        "Here, one variable **directly influences** the other.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Difference Between Correlation and Causation**\n",
        "\n",
        "| Concept | Meaning | Relationship Between Variables |\n",
        "|---------|---------|--------------------------------|\n",
        "| **Correlation** | Two variables move together (positively or negatively) | They are related, but one may NOT cause the other |\n",
        "| **Causation** | One variable produces change in another | Direct cause-and-effect relationship |\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Key Point**\n",
        "\n",
        "> **Correlation does NOT always imply causation.**\n",
        "\n",
        "Just because two things are correlated does **not** mean one causes the other.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Example to Understand the Difference**\n",
        "\n",
        "| Scenario | Interpretation |\n",
        "|----------|---------------|\n",
        "| **Correlation** | Ice cream sales and drowning cases both increase during summer. |\n",
        "| **Does one cause the other?** | No. Summer heat increases swimming and ice cream sales ‚Üí common factor. |\n",
        "| **Conclusion** | They are correlated but there is **no causation**. |\n",
        "\n",
        "Another clearer example:\n",
        "\n",
        "| Variables | Observation |\n",
        "|----------|-------------|\n",
        "| Amount of time spent studying ‚Üë | Exam scores ‚Üë |\n",
        "\n",
        "- **This shows causation** because studying directly affects learning ‚Üí improves performance.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Visual Understanding**\n",
        "\n"
      ],
      "metadata": {
        "id": "YG2Vc18bfmDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgENC2Qqfw9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 16: What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What is an Optimizer?**\n",
        "\n",
        "In Machine Learning and Deep Learning, an **optimizer** is an algorithm that **updates the parameters of a model (weights and biases) to minimize the loss function**.\n",
        "\n",
        "During training, the model makes predictions ‚Üí calculates loss (error) ‚Üí the optimizer adjusts the parameters to **reduce the error step-by-step**.\n",
        "\n",
        "In simple words:\n",
        "> **Optimizer improves the model by reducing errors and increasing accuracy.**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why Optimizers are Important**\n",
        "\n",
        "Without an optimizer:\n",
        "- Model will not learn\n",
        "- Weights will not update\n",
        "- Accuracy will not improve\n",
        "\n",
        "Optimizers guide the model toward **best parameters** that produce **minimum loss**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Different Types of Optimizers**\n",
        "\n",
        "Below are the most commonly used optimizers in Deep Learning:\n",
        "\n",
        "---\n",
        "\n",
        "#### **A. Gradient Descent (GD ‚Äî Batch Gradient Descent)**\n",
        "\n",
        "- Updates weights using **entire dataset** in each step.\n",
        "- Stable but **slow** for large datasets.\n",
        "\n",
        "**Update rule**\n",
        "\\[\n",
        "w = w - \\alpha \\cdot \\frac{\\partial Loss}{\\partial w}\n",
        "\\]\n",
        "\n",
        "**Example**\n",
        "Training a Linear Regression model using all rows of the dataset to update weights after each epoch.\n",
        "\n",
        "---\n",
        "\n",
        "#### **B. Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "- Updates weights **for each training example**.\n",
        "- **Faster** than GD but noisy updates.\n",
        "\n",
        "**Example**\n",
        "If a dataset has 500 rows, SGD updates weights **500 times per epoch**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **C. Mini-Batch Gradient Descent (Most common)**\n",
        "\n",
        "- Updates weights using **small batches** of data (e.g., 32, 64).\n",
        "- Balance between **speed and stability**.\n",
        "\n",
        "**Example**\n",
        "Dataset has 10,000 samples ‚Üí divided into batches of 64 ‚Üí model updates weights many times per epoch.\n",
        "\n",
        "---\n",
        "\n",
        "#### **D. Momentum Optimizer**\n",
        "\n",
        "- Adds **momentum** to the update to avoid oscillations.\n",
        "- Helps speed up learning and escape local minima.\n",
        "\n",
        "**Example**\n",
        "Like rolling a ball downhill ‚Äî momentum pushes faster toward minimum.\n",
        "\n",
        "---\n",
        "\n",
        "#### **E. AdaGrad (Adaptive Gradient Descent)**\n",
        "\n",
        "- Uses **different learning rates for each parameter**.\n",
        "- Good for sparse (imbalanced) data.\n",
        "\n",
        "**Example**\n",
        "Useful in NLP problems where some words appear rarely.\n",
        "\n",
        "---\n",
        "\n",
        "#### **F. RMSProp (Root Mean Square Propagation)**\n",
        "\n",
        "- Fixes AdaGrad‚Äôs decreasing learning rate problem.\n",
        "- Works well on **sequential data** such as RNNs.\n",
        "\n",
        "**Example**\n",
        "Training speech recognition or time-series models.\n",
        "\n",
        "---\n",
        "\n",
        "#### **G. Adam (Most widely used)**\n",
        "\n",
        "Adam = **Momentum + RMSProp**\n",
        "- Adaptive learning rate\n",
        "- Works with most deep learning models\n",
        "- Fast convergence and high performance\n",
        "\n",
        "**Example**\n",
        "Used for CNNs, RNNs, Transformers (NLP), etc.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Summary Table of Optimizers**\n",
        "\n",
        "| Optimizer | Uses Full Data? | Speed | Best For |\n",
        "|----------|------------------|--------|----------|\n",
        "| Gradient Descent | Yes | Slow | Small datasets |\n",
        "| SGD | No (one sample at a time) | Fast but unstable | Large datasets |\n",
        "| Mini-Batch GD | No (small batch) | Fast + stable | Deep learning |\n",
        "| Momentum | No | Faster convergence | Deep learning |\n",
        "| AdaGrad | No | Adjusts learning rate | Sparse data |\n",
        "| RMSProp | No | Works well on sequence data | RNNs |\n",
        "| Adam | No | Fast & most stable | Almost all DL models |\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Real-Life Analogy**\n",
        "\n",
        "Training a model is like **finding the lowest point in a valley (minimum loss)**:\n",
        "\n",
        "| Optimizer | Analogy |\n",
        "|----------|----------|\n",
        "| GD | Carefully checking the entire mountain before taking one step |\n",
        "| SGD | Taking fast steps but sometimes in the wrong direction |\n",
        "| Mini-Batch | Balanced and smart steps |\n",
        "| Momentum | Running and gaining speed downhill |\n",
        "| Adam | Running downhill with speed + intelligence |\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Code Example (how optimizers are used in practice)**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "cBdYSNikfxpb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXMlczWvfmcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 17: What is `sklearn.linear_model` ?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Simple Definition**\n",
        "\n",
        "`sklearn.linear_model` is a **module in Scikit-Learn (sklearn)** that provides **machine learning algorithms based on linear models**.\n",
        "\n",
        "These algorithms make predictions by assuming a **linear relationship** between the input features (X) and the output target (y).\n",
        "\n",
        "In simple words:\n",
        "> `sklearn.linear_model` contains models that try to fit a **straight-line or linear equation** to the data.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What can `sklearn.linear_model` be used for?**\n",
        "\n",
        "It is used for:\n",
        "| Task | Models Available |\n",
        "|------|------------------|\n",
        "| Regression (predicting continuous values) | LinearRegression, Ridge, Lasso, ElasticNet |\n",
        "| Classification (predicting categories) | LogisticRegression, SGDClassifier |\n",
        "| Probabilistic models | BayesianRidge |\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Popular Models inside `sklearn.linear_model`**\n",
        "\n",
        "| Model | Type | Purpose |\n",
        "|-------|------|---------|\n",
        "| `LinearRegression()` | Regression | Predicts continuous numeric output (e.g., price, marks) |\n",
        "| `LogisticRegression()` | Classification | Predicts class labels (e.g., spam / not spam) |\n",
        "| `Ridge()` | Regression | L2 regularization to reduce overfitting |\n",
        "| `Lasso()` | Regression | L1 regularization for feature selection |\n",
        "| `ElasticNet()` | Regression | Combination of Ridge + Lasso |\n",
        "| `SGDClassifier()` | Classification | Uses stochastic gradient descent for large datasets |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Example: Linear Regression using `sklearn.linear_model`**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4],\n",
        "    \"Marks\": [45, 88, 60, 92, 65]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "X = df[[\"Hours_Studied\"]]  # input\n",
        "y = df[\"Marks\"]            # output\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict marks for 6 hours of study\n",
        "prediction = model.predict([[6]])\n",
        "print(\"Predicted Marks:\", prediction)\n"
      ],
      "metadata": {
        "id": "Yus3qG5ofmxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4],\n",
        "    \"Marks\": [45, 88, 60, 92, 65]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "X = df[[\"Hours_Studied\"]]  # input\n",
        "y = df[\"Marks\"]            # output\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict marks for 6 hours of study\n",
        "prediction = model.predict([[6]])\n",
        "print(\"Predicted Marks:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wta0DIWjglXX",
        "outputId": "e0585a64-3fe0-46f7-d78d-618861cb0ec7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Marks: [82.52830189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uz-GG1ZdgqEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 18: What does model.fit() do? What arguments must be given?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What does `model.fit()` do?**\n",
        "\n",
        "In Machine Learning, `model.fit()` is the function used to **train the model**.\n",
        "\n",
        "It means:\n",
        "\n",
        "‚û°Ô∏è The model **learns patterns** from the training data  \n",
        "‚û°Ô∏è It adjusts its internal parameters to **reduce error**  \n",
        "‚û°Ô∏è It prepares the model to make predictions on new data\n",
        "\n",
        "So, `fit()` = **learning step of the model**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Arguments required in `model.fit()`**\n",
        "\n",
        "Usually, `fit()` needs **two main arguments**:\n",
        "\n",
        "| Argument | Meaning |\n",
        "|---------|---------|\n",
        "| **X** | Input features (independent variables) |\n",
        "| **y** | Target/output (dependent variable) |\n",
        "\n",
        "Example:\n",
        "- X = height, age, weight  \n",
        "- y = diabetes (Yes/No)\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Basic Syntax**\n",
        "\n",
        "```python\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Extra optional arguments**\n",
        "\n",
        "Sometimes we also use:\n",
        "\n",
        "| Argument | Purpose |\n",
        "|---------|---------|\n",
        "| `epochs` | Number of times to train (deep learning) |\n",
        "| `batch_size` | Samples processed before model update |\n",
        "| `validation_data` | Data to evaluate model during training |\n",
        "| `verbose` | Display training progress |\n",
        "\n",
        "These appear mostly in **Neural Networks / Deep Learning**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example in Python**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "Here:\n",
        "\n",
        "- `X_train` ‚Üí input training data  \n",
        "- `y_train` ‚Üí target values  \n",
        "\n",
        "---\n",
        "\n",
        "### **In simple words**\n",
        "\n",
        "`model.fit()` = **train the model using input data and correct output**  \n",
        "So the model learns the relationship between **X ‚Üí y**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jmpHsuNYgqly"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0b8fEZqGhZ6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 19: What does model.predict() do? What arguments must be given?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---\n",
        "\n",
        "### üîç **What does `model.predict()` do?**\n",
        "\n",
        "The function **`model.predict()`** is used to **make predictions** using a trained Machine Learning model.\n",
        "\n",
        "It takes **new/unseen input data** and returns the **predicted output** based on what the model has learned during training.\n",
        "\n",
        "In simple words:\n",
        "\n",
        "‚û°Ô∏è **model.fit() = learn from data**  \n",
        "‚û°Ô∏è **model.predict() = give prediction for new data**\n",
        "\n",
        "---\n",
        "\n",
        "### üìå **Arguments required**\n",
        "\n",
        "`model.predict()` usually requires **only one argument:**\n",
        "\n",
        "| Argument | Meaning |\n",
        "|----------|---------|\n",
        "| **X_test / new_data** | The feature input data for which you want the prediction |\n",
        "\n",
        "The input must be **in the same format and number of features** that were used during training.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Example (Simple)\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # training the model\n",
        "\n",
        "y_pred = model.predict(X_test)  # predicting on test data\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Output\n",
        "\n",
        "- Regression model ‚Üí predicted **continuous values**\n",
        "- Classification model ‚Üí predicted **class labels** (e.g., \"spam\" or \"not spam\")\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Important Notes\n",
        "\n",
        "- `model.predict()` **does not re-train** the model ‚Äî it only **uses the learned pattern**.\n",
        "- The input **must match the shape and features** used during training.\n",
        "- It can also be used for **real-world prediction** once the model is deployed.\n",
        "\n",
        "---\n",
        "\n",
        "### **In short:**\n",
        "\n",
        "| Function | Purpose |\n",
        "|---------|----------|\n",
        "| `model.fit()` | Trains the model using features and target |\n",
        "| `model.predict()` | Predicts output for new/unseen data |\n",
        "\n",
        "‚û°Ô∏è **`model.predict()` gives the final result of the Machine Learning model.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Q5Ha29QJhaYY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UOwlbZQ1hsN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 20: What are continuous and categorical variables?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **1. Continuous Variables**\n",
        "\n",
        "Continuous variables are **numerical values that can take any value within a range**.  \n",
        "They can include **decimals or fractions** and have **infinite possible values**.\n",
        "\n",
        "#### **Examples**\n",
        "- Height (e.g., 168.4 cm)\n",
        "- Weight (e.g., 55.72 kg)\n",
        "- Temperature (e.g., 37.5¬∞C)\n",
        "- Salary (e.g., ‚Çπ45,250.75)\n",
        "\n",
        "#### **Key Points**\n",
        "- Always **numerical**\n",
        "- Values can be **measured**\n",
        "- Can take **decimal values**\n",
        "\n",
        "---\n",
        "\n",
        "### üî∑ **2. Categorical Variables**\n",
        "\n",
        "Categorical variables represent **groups, labels, or categories** instead of numeric measurements.  \n",
        "They tell **which category** something belongs to.\n",
        "\n",
        "#### **Examples**\n",
        "- Gender (Male, Female)\n",
        "- City (Mumbai, Pune, Delhi)\n",
        "- Color (Red, Blue, Green)\n",
        "- Education (Diploma, Graduate, Post-graduate)\n",
        "\n",
        "#### **Key Points**\n",
        "- Indicates **category or group**\n",
        "- Can be **text labels or numbers used as labels**\n",
        "- Can be divided into:\n",
        "  - **Nominal variables** ‚Üí No ranking (e.g., colors)\n",
        "  - **Ordinal variables** ‚Üí Have order/ranking (e.g., poor, average, good, excellent)\n",
        "\n",
        "---\n",
        "\n",
        "### üîç **Difference in Simple Words**\n",
        "\n",
        "| Feature | Continuous Variable | Categorical Variable |\n",
        "|--------|---------------------|-----------------------|\n",
        "| Type of data | Numbers | Labels / Groups |\n",
        "| Values | Infinite & measurable | Limited & grouped |\n",
        "| Examples | Height, marks, salary | Gender, city, color |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚≠ê Easy Trick to Remember\n",
        "- **If you can measure ‚Üí Continuous**\n",
        "- **If you can group ‚Üí Categorical**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "s73FTe26hsob"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pVRPB84wiAF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 21: What is feature scaling? How does it help in Machine Learning?**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What is Feature Scaling?**\n",
        "\n",
        "**Feature scaling** is a preprocessing technique used to **transform numerical data into a common scale without changing the shape of the distribution**.\n",
        "\n",
        "Different features in a dataset may have different units and ranges (e.g., age 1‚Äì100, salary 10,000‚Äì100,000), and machine learning models work better when the values are on a **similar scale**.\n",
        "\n",
        "In simple words:\n",
        "> Feature scaling makes all numerical features comparable by adjusting their ranges.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why is Feature Scaling Important in Machine Learning?**\n",
        "\n",
        "Without scaling, features with large values may **dominate the learning process**, causing:\n",
        "- Slow training\n",
        "- Bias toward large-scale features\n",
        "- Poor model performance\n",
        "\n",
        "With scaling:\n",
        "- All features contribute equally\n",
        "- Gradient descent converges faster\n",
        "- Model accuracy increases\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Algorithms That Require Feature Scaling**\n",
        "\n",
        "| Scaling Required | No Scaling Needed (mostly) |\n",
        "|------------------|----------------------------|\n",
        "| KNN | Decision Trees |\n",
        "| SVM | Random Forest |\n",
        "| Logistic Regression | XGBoost |\n",
        "| Linear Regression | Naive Bayes |\n",
        "| Neural Networks | Rule-based algorithms |\n",
        "| K-Means | ‚Äî |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Common Methods of Feature Scaling**\n",
        "\n",
        "| Method | Range | When to Use |\n",
        "|--------|--------|-------------|\n",
        "| **Standardization (Z-score Scaling)** | Mean = 0, Std = 1 | Works well with normal distribution |\n",
        "| **Normalization (Min-Max Scaling)** | 0 to 1 | Good for deep learning & distance-based models |\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Examples**\n",
        "\n",
        "#### **Normalization (Min-Max Scaling)**  \n",
        "\\[\n",
        "X' = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
        "\\]\n",
        "\n",
        "#### **Standardization (Z-score Scaling)**  \n",
        "\\[\n",
        "X' = \\frac{X - \\mu}{\\sigma}\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### **6. How Scaling Helps (Summary)**\n",
        "\n",
        "Feature scaling improves machine learning by:\n",
        "- Making all features contribute equally\n",
        "- Helping gradient descent reach minimum faster\n",
        "- Improving performance of distance-based algorithms\n",
        "- Avoiding numerical instability\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Takeaway**\n",
        "\n",
        "> Feature scaling does **not change the meaning of data**, but it improves how efficiently and accurately a machine learning model learns.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "z-57z3BfiAhN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IL7hRFBoilqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 22: How do we perform scaling in Python?**\n",
        "\n",
        "Feature scaling in Python is most commonly done using the **`sklearn.preprocessing`** module. The two most widely used methods are **Standardization** and **Normalization**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Standardization (Z-score Scaling)**\n",
        "\n",
        "Transforms data so that:\n",
        "- Mean = 0  \n",
        "- Standard deviation = 1  \n",
        "\n",
        "‚úî Useful for algorithms like Logistic Regression, SVM, KNN, Neural Networks.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\"Age\": [18, 25, 31, 40, 50], \"Salary\": [20000, 35000, 50000, 65000, 90000]})\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "print(\"Standardized Data:\\n\", scaled_data)\n"
      ],
      "metadata": {
        "id": "hvjlbZWkimWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"Age\": [18, 25, 31, 40, 50], \"Salary\": [20000, 35000, 50000, 65000, 90000]})\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_data = scaler.fit_transform(df)\n",
        "\n",
        "print(\"Normalized Data:\\n\", normalized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7VkolNviv7i",
        "outputId": "7bfbf5ad-2d60-4175-808a-e585bd7f5236"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Data:\n",
            " [[0.         0.        ]\n",
            " [0.21875    0.21428571]\n",
            " [0.40625    0.42857143]\n",
            " [0.6875     0.64285714]\n",
            " [1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "LWkTXfkji7FL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "alyp76oOjMis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 23: What is `sklearn.preprocessing`?**\n",
        "\n",
        "`sklearn.preprocessing` is a **module in Scikit-Learn (sklearn)** that contains tools used to **prepare and transform raw data before training a machine learning model**.  \n",
        "Preprocessing improves the quality of data so that the model can learn patterns more effectively.\n",
        "\n",
        "In simple words:\n",
        "> `sklearn.preprocessing` helps convert raw, unscaled, or categorical data into a clean and numerical format suitable for machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "### **What can `sklearn.preprocessing` do? (Main Functions)**\n",
        "\n",
        "| Task | Tool/Method | Purpose |\n",
        "|------|-------------|---------|\n",
        "| Scaling numerical values | `StandardScaler`, `MinMaxScaler`, `Normalizer` | Puts features on the same scale |\n",
        "| Encoding categorical values | `LabelEncoder`, `OneHotEncoder`, `OrdinalEncoder` | Converts text labels into numbers |\n",
        "| Binarization | `Binarizer` | Converts values into 0/1 based on a threshold |\n",
        "| Feature transformation | `PolynomialFeatures` | Creates polynomial combinations of features |\n",
        "| Normalizing samples | `normalize()` | Converts data to unit norm |\n",
        "\n",
        "---\n",
        "\n",
        "### **Example Usage**\n",
        "\n",
        "#### **1. Feature Scaling**\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_X = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "SE5MAnaUiBT9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GcQeevD6jU_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 24: How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "To train and evaluate a machine learning model properly, the dataset must be divided into:\n",
        "- **Training Set** ‚Üí used to train (fit) the model\n",
        "- **Testing Set** ‚Üí used to evaluate the model on unseen data\n",
        "\n",
        "In Python, we use the function **`train_test_split`** from **`sklearn.model_selection`**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example (Detailed in ONE Cell)**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4, 6, 1, 7, 9, 5],\n",
        "    \"Attendance\":    [60, 90, 75, 95, 70, 88, 55, 92, 98, 85],\n",
        "    \"Marks\":         [45, 88, 60, 92, 65, 80, 35, 89, 96, 78]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separating features (X) and target (y)\n",
        "X = df[[\"Hours_Studied\", \"Attendance\"]]   # input variables\n",
        "y = df[\"Marks\"]                           # target values\n",
        "\n",
        "# Splitting dataset: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Set Shape :\", X_train.shape, \"|\", y_train.shape)\n",
        "print(\"Testing Set Shape  :\", X_test.shape,  \"|\", y_test.shape)\n",
        "print(\"\\nTraining Data:\\n\", pd.concat([X_train, y_train], axis=1))\n",
        "print(\"\\nTesting Data:\\n\", pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "id": "4QreiaTpjVlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [2, 5, 3, 8, 4, 6, 1, 7, 9, 5],\n",
        "    \"Attendance\":    [60, 90, 75, 95, 70, 88, 55, 92, 98, 85],\n",
        "    \"Marks\":         [45, 88, 60, 92, 65, 80, 35, 89, 96, 78]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separating features (X) and target (y)\n",
        "X = df[[\"Hours_Studied\", \"Attendance\"]]   # input variables\n",
        "y = df[\"Marks\"]                           # target values\n",
        "\n",
        "# Splitting dataset: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Set Shape :\", X_train.shape, \"|\", y_train.shape)\n",
        "print(\"Testing Set Shape  :\", X_test.shape,  \"|\", y_test.shape)\n",
        "print(\"\\nTraining Data:\\n\", pd.concat([X_train, y_train], axis=1))\n",
        "print(\"\\nTesting Data:\\n\", pd.concat([X_test, y_test], axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJWBh_kViB1T",
        "outputId": "9dcd4601-f542-4082-a258-ff51a0efcd9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape : (8, 2) | (8,)\n",
            "Testing Set Shape  : (2, 2) | (2,)\n",
            "\n",
            "Training Data:\n",
            "    Hours_Studied  Attendance  Marks\n",
            "5              6          88     80\n",
            "0              2          60     45\n",
            "7              7          92     89\n",
            "2              3          75     60\n",
            "9              5          85     78\n",
            "4              4          70     65\n",
            "3              8          95     92\n",
            "6              1          55     35\n",
            "\n",
            "Testing Data:\n",
            "    Hours_Studied  Attendance  Marks\n",
            "8              9          98     96\n",
            "1              5          90     88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MvcCWyY_j29B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 25: Explain Data Encoding\n",
        "\n",
        "**Data encoding** means **converting text data into numbers** so that a machine learning model can understand it.\n",
        "\n",
        "Machines cannot learn from words like:\n",
        "- \"Male\", \"Female\"\n",
        "- \"Red\", \"Blue\"\n",
        "- \"Mumbai\", \"Delhi\"\n",
        "\n",
        "So we convert them into numbers.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why do we need encoding?**\n",
        "Because ML models do **math**, and math works only with **numbers**, not **words**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Common Methods of Encoding (Simple Explanation)**\n",
        "\n",
        "| Method | Simple Meaning | Example |\n",
        "|--------|----------------|---------|\n",
        "| **Label Encoding** | Give a number to each category | Mumbai ‚Üí 0, Delhi ‚Üí 1, Pune ‚Üí 2 |\n",
        "| **One-Hot Encoding** | Create separate column for each category with 0/1 | City_Mumbai, City_Delhi, City_Pune |\n",
        "| **Ordinal Encoding** | Give numbers based on rank/order | Low ‚Üí 1, Medium ‚Üí 2, High ‚Üí 3 |\n",
        "\n",
        "---\n",
        "\n",
        "### **In short**\n",
        "> Encoding converts words into numbers so that the ML model can understand and learn from data.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cuvweJKZkBCQ"
      }
    }
  ]
}